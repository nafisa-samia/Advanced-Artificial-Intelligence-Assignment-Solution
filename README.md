# Deep-Reinforcement-Learning

## Exercises


---


a) Linearly decaying learning rate

Depending on the current episode let the learning rate decay linearly.


---


b) Normalizing returns

Normalize the already computed returns that are used for the loss.

Hint: You might need to call these tensor functions: .mean(), .std()


---


c) Neural Network Architecture

Change the activation function or the size of the neural net.

e.g. add a hidden layer
e.g. change the number of units in a layer
e.g. use nn.LeakyReLU instead of nn.ReLU


---


d) Compare your results using Tensorboard.
Important: Change the run_id for each run!


---

e) Test another environment.

Classic Control Environemtns: https://gym.openai.com/envs/#classic_control

MountainCar-v0

Acrobot-v1

Pendulum-v0


